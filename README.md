# Line and Plane based Incremental Surface Reconstruction


This is a real-time surface reconstruction method using Planar features from the scene. The semi-dense point cloud generated by ORB-SLAM is simplified into 3D lines segments using an approach similar to [He et al](https://arxiv.org/pdf/1708.03275). We further simplify the map by detecting planes from 3D interesecting lines segments. These planes are matched in every keyframe for consistency. We cluster the lines based on the planar regions they lie in. The points on these lines are used to reconstruct 3D surface using a lightweight 3D Delaunay Triangulation based free-space carving approach [CARV](https://arxiv.org/abs/1903.09189).

This version of software is based on [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2). However we made significant change to the code to make it work on lateset OPENCV and ROS version as of December 2022. We release this software under GPLv3 license.

For more details on the maths,theory, and experimental results of this system follow the webpage of this project: [PlaneSlam](https://sites.google.com/ualberta.ca/planeslam)

 ![Overview](https://github.com/imjunaida/Line-Plane-CARV/assets/30365313/355a0cb7-589d-45cc-9370-6fea48aa567e)




# 1. Prerequisites
The software is tested in **64-bit Ubuntu 20.04**.


#### C++14 Compiler
Normal ORB-SLAM works on c++11 but we updated it to work with c++14 standard

#### Pangolin
We use [Pangolin](https://github.com/stevenlovegrove/Pangolin) for visualization and user interface. Dowload and install instructions can be found at: https://github.com/stevenlovegrove/Pangolin. Tested on 0.5v of Pangolin. Latest version does not allow deprecated functions.

#### OpenCV
We use [OpenCV](http://opencv.org) to manipulate images and features. Dowload and install instructions can be found at: http://opencv.org. **Required at leat 2.4.3. Tested with OpenCV 4.2.0**.

#### Eigen3
Required by g2o (see below). Download and install instructions can be found at: http://eigen.tuxfamily.org. **Required at least 3.1.0**.

#### BLAS and LAPACK
[BLAS](http://www.netlib.org/blas) and [LAPACK](http://www.netlib.org/lapack) libraries are requiered by g2o (see below). On ubuntu:
```
sudo apt-get install libblas-dev liblapack-dev liblapacke-dev
```

#### DBoW2 and g2o (Included in Thirdparty folder)
We use modified versions of the [DBoW2](https://github.com/dorian3d/DBoW2) library to perform place recognition and [g2o](https://github.com/RainerKuemmerle/g2o) library to perform non-linear optimizations. Both modified libraries (which are BSD) are included in the *Thirdparty* folder.

#### ROS (For working on real camera input)
We domonstrate the complete method to use a USB camera for image stream. The system is tested on ROS-noetic.

## Additional
Apart from the dependencies list above for ORB-SLAM2, additional libraries are needed.

#### CGAL: 
```
sudo apt-get install libcgal-dev
```
#### Boost:
```
sudo apt-get install libboost-all-dev
```


# 2. Building

Similar to ORB-SLAM2, `build.sh` can build the Third Party libraries and the surface reconstruction module. Please make sure you have installed all required dependencies (see section 1). 

Execute:
```
chmod +x build.sh
./build.sh
```

For building the ROS script you need to export the ROS_PACKAGE_PATH to your source directory. Later source the bash file before running.

```
export ROS_PACKAGE_PATH = ${ROS_PACKAGE_PATH}: #path_to_file/Examples/ROS/
```

```
chmod +x build_ros.sh 
./ build_ros.sh
```
```
source Examples/ROS/ORB_SLAM2/build/devel/setup.bash
```

# 3. Running the modules
We used cv_camera module of ROS to get image streams from camera.

Check the list of devices for parameter cv_camera/device_id
```
v4l2-ctl --list-devices
```
Run roscore and set ROS parameters: device_id, Optional(image_width, image_height)

```
roscore
rosparam set /cv_camera/device_id #num
rosrun cv_camera cv_camera_node
```

Running ORB_SLAM2 with surface reconstruction

```
rosrun ORB_SLAM2 Mono Vocabulary/ORBvoc.bin #path_to_calibration_file/*.yaml /camera/image_raw:=/cv_camera/image_raw
```
The object files get saved in the Object Files directory in real-time which can be used by a real-time modeling software.

# 4. Running using the Docker Image
Run the roscore and hte cv_camera module as done in part 3. Instead of the *rosrun ORB_SLAM2 Mono Vocabulary/ORBvoc.bin #path_to_calibration_file/*.yaml /camera/image_raw:=/cv_camera/image_raw* run the following statement
```
#Set host local
host local:
# Now run the docker image named carv:latest
sudo docker run --rm -e DISPLAY=$DISPLAY -v /temp/.X11-unix --gpus=all --privileged --network host --env QT_X11_NO_MITSHM=1 -it kesisci/carv:latest /bin/bash
```
**Note**: Don't forget to source the setup files as done in part 2. It is one of the common mistakes to simply forget about our good old source files. 

# Important Repositories
1. [ORB-SLAM Free Space Carving](https://github.com/atlas-jj/ORB-SLAM-free-space-carving)
2. [Incremental 3D Line Segment Extraction](https://github.com/shidahe/semidense-lines)

